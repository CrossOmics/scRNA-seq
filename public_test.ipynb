{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pip install cplearn #Install this pacakge.",
   "id": "6308aed1fa8db22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Load data here.\n",
    "X=None #X will be an n*d numpy array. Most likely either the post-PCA or post-harmony dataset."
   ],
   "id": "f06728ab7465c595",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from cplearn.corespect import Corespect\n",
    "corespect = Corespect(X)\n",
    "core = corespect.find_core(core_fraction=0.15)\n",
    "#{\"k\": true_k}\n",
    "cluster_core = corespect.cluster_core(core, cluster_algo='louvain',cluster_algo_params={\"ng_num\": 20,\"resolution\":1})\n",
    "propagated_data = corespect.propagate_labels(cluster_core, propagate_algo='adaptive_majority', propagate_algo_params={\"ng_num\": 20})"
   ],
   "id": "ba4a95f09619f4fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from cplearn.visualizer import Visualizer as viz\n",
    "# 4. Extract layers and labels\n",
    "layers, labels_for_layer = propagated_data.get_layers_and_labels(mode_choice='three_steps')\n",
    "#The first layers are cores. These are the most separable parts."
   ],
   "id": "17373b615805b413",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 5. Visualize (Visualizer internally calls CoreMAP for embedding)\n",
    "mode_choice='three_steps' #use this with adaptive_majority\n",
    "#You can use mode_choice='layerwise' to see a more in-depth layer-by-layer visualization\n",
    "#Use layerwise if propagate_algo is \"CDNN\"\n",
    "fig = viz(corespect,mode=mode_choice).fig\n",
    "\n"
   ],
   "id": "6d39c24d66fb9d4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#In the output html file, click on \"FlowRank\" on the line that says core.\n",
    "#Then click on the \"louvain\" button in the next line\n",
    "#Finally, click on the \"adaptive majority\" button\n",
    "#Now, a scrollbar will appear at the bottom of the image. You can move it from left to right, and observe visualization of the core (central points) to periphery (boundary points) (colored using labels found by CoreSPECT)\"\n",
    "\n",
    "fig.show()   # or fig.write_html(\"corespect_viz.html\")"
   ],
   "id": "e13f67e7c8b13651",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#We also have functionality where you can run multiple clustering/propagation steps on the same data, and then be able to access them in a user-friendly manner, as well as be able to observe their visualizations collectively for smooth comparisons. The functionality already exists in our cplearn package and we will share a detailed description/vignette for direction soon.",
   "id": "daa5abff93c1c811",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
